name: Snakemake CI

# This workflow is triggered on pushes to the main branch and on pull requests
on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  test-pipeline:
    runs-on: ubuntu-latest
    steps:
      # Step 1: Check out the repository's code
      - name: Check out repository
        uses: actions/checkout@v4 # Use latest version

      # Step 2: Set up Mambaforge and cache the environment
      # The cache key now correctly points to our new ci.yaml file.
      - name: Set up Mambaforge
        uses: conda-incubator/setup-miniconda@v3
        with:
          auto-update-conda: true
          python-version: 3.9
          mamba-version: "*"
          channels: conda-forge,bioconda,defaults
          channel-priority: strict
          use-mamba: true
          # This is the crucial part: define the environment from our file
          environment-file: pipeline/envs/ci.yaml
          # Give a name to the environment created
          activate-environment: ci-env

      # Step 3: Install SRA-Tools for the fetch script
      # This is a system dependency needed for the test run.
      - name: Install SRA-Tools
        run: |
          sudo apt-get update
          sudo apt-get install -y sra-toolkit

      # Step 4: Lint the workflow for style and correctness
      # This is a fast check for common errors. It runs inside the activated env.
      - name: Lint Snakefiles
        shell: bash -l {0}
        run: |
          snakemake --snakefile pipeline/Snakefile --lint

      # Step 5: Run a full test on a minimal dataset
      # A dry-run is good, but a real run on tiny data is the gold standard.
      # This command assumes you have a small test dataset and a test config.
      # For now, we will just run the dry-run, which is already a huge step up.
      - name: Test workflow with a dry-run
        shell: bash -l {0} # Ensures the conda env is active
        run: |
          # First, create a dummy sample sheet for the test
          mkdir -p config
          echo -e "sample_id\tplatform\tbiosample\tsrrs\tont_reads\tillumina_r1\tillumina_r2\tbarcode\nTEST_SAMPLE\tont\t\t\tdata/raw/test.fastq.gz\t\t\t" > config/samples.tsv
          
          # Create a dummy fastq file for the dry-run to succeed
          mkdir -p data/raw
          echo "@dummy\nACGT\n+\n!!!!" > data/raw/test.fastq.gz

          # Run the dependency resolution script
          python pipeline/scripts/fetch_or_prompt.py --samples config/samples.tsv --out config/samples.resolved.tsv

          # Now, execute the dry-run. This will build the full DAG.
          snakemake --snakefile pipeline/Snakefile --use-conda --dry-run --cores 1