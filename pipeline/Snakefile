# =========================
# File: pipeline/Snakefile
# =========================

from pathlib import Path
from os import getenv

print("[DEBUG workflow.basedir] " + str(workflow.basedir))

PIPELINE_DIR = Path(workflow.basedir).resolve()
REPO = PIPELINE_DIR.parent

WF_DIR = PIPELINE_DIR
CFG_DIR = REPO / "config"
SCRIPTS_DIR = REPO / "scripts"
RULES_DIR = PIPELINE_DIR / "rules"

# Guarded DOC_TEMPLATE (avoid None.exists() crashes downstream)
try:
    _doc_template_cfg = config.get("doc_template") if isinstance(config, dict) else None
except NameError:
    _doc_template_cfg = None

DOC_TEMPLATE = _doc_template_cfg or str(REPO / "docs" / "templates" / "run_manifest_template.tsv")
try:
    if not Path(DOC_TEMPLATE).exists():
        DOC_TEMPLATE = None
except Exception:
    DOC_TEMPLATE = None

include: str(RULES_DIR / "io.smk")
include: str(RULES_DIR / "validate_manifest.smk")

print("[DEBUG REPO] " + str(REPO))
assert "site-packages" not in str(REPO), "Unexpected site-packages REPO: " + str(REPO)

CONFIG = CFG_DIR / "config.yaml"

def cfg(path, default=None):
    try:
        d = config
    except NameError:
        return default
    if not isinstance(d, dict):
        return default
    cur = d
    keys = path.split(".")
    for i, k in enumerate(keys):
        if not isinstance(cur, dict):
            return default
        cur = cur.get(k, default if i == len(keys) - 1 else {})
    return cur if cur is not None else default

# --------------------------------------------------------------------
# Paths and fetch configuration
# --------------------------------------------------------------------
FETCH_ENABLE = bool(cfg("fetch.enable", True))
FETCH_NON_INTERACTIVE = bool(cfg("fetch.non_interactive", False))
FETCH_THREADS = int(cfg("fetch.threads", 4))
FETCH_SCRIPT = cfg("fetch.script", str(SCRIPTS_DIR / "fetch_or_prompt.py"))
FETCH_NON_INTERACTIVE_FLAG = "--non-interactive" if FETCH_NON_INTERACTIVE else ""
FETCH_ENABLE_STR = "true" if FETCH_ENABLE else "false"

MANIFESTS_GLOB = str(REPO / "data" / "manifests" / "*.tsv")
SAMPLES_TSV_IN = (REPO / cfg("fetch.samples", "config/samples.tsv")).resolve()
SAMPLES_TSV_OUT = (REPO / cfg("fetch.out", "config/samples.resolved.tsv")).resolve()

print("Resolved paths:")
print(f"  REPO        = {REPO}")
print(f"  CONFIG      = {CONFIG} (exists={CONFIG.exists()})")
print(f"  SAMPLES_IN  = {SAMPLES_TSV_IN} (exists={SAMPLES_TSV_IN.exists()})")
print(f"  SAMPLES_OUT = {SAMPLES_TSV_OUT}")
print(f"  SCRIPTS_DIR = {SCRIPTS_DIR} (exists={SCRIPTS_DIR.exists()})")

# --------- Lazy helpers (no file access at parse time) ----------
def samples_list():
    # io.smk should provide read_samples(tsv_path)
    return read_samples(str(SAMPLES_TSV_OUT))

def raw_reads_dict():
    # io.smk should provide raw_read_path(sample_id)
    return {s: raw_read_path(s) for s in samples_list()}

# =========================
# Build config/samples.tsv (Schema B) from manifests if missing
# =========================
rule build_samples_from_manifests:
    output:
        str(SAMPLES_TSV_IN)
    message:
        "Generating config/samples.tsv from manifests: {wildcards}"
    run:
        import subprocess, shlex, os
        os.makedirs(os.path.dirname(output[0]) or ".", exist_ok=True)
        cmd = [
            "python", str(SCRIPTS_DIR / "manifest_to_samples.py"),
            "--manifests_glob", MANIFESTS_GLOB,
            "--out", output[0],
            "--default-platform", "ont",
        ]
        subprocess.check_call(cmd)

# =========================
# Manifest validation (A+)
# =========================
rule validate_manifests:
    input:
        "reports/manifest_validation.txt",
        "reports/manifest_validation.json"
    message:
        "Manifest validation reports ready."

# ---------------------------------
# Resolve/fetch to produce samples.resolved.tsv
# ---------------------------------
rule resolve_samples:
    input:
        samples=str(SAMPLES_TSV_IN)
    output:
        out=str(SAMPLES_TSV_OUT)
    threads:
        FETCH_THREADS
    conda:
        "envs/fetch.yaml"
    message:
        "Resolving/Fetching FASTQs -> {output.out}"
    shell:
        """
        set -euo pipefail
        if [ "{FETCH_ENABLE_STR}" = "true" ]; then
            python {FETCH_SCRIPT} \
              --samples {input.samples} \
              --out {output.out} \
              --threads {threads} \
              --non-interactive \
              --skip-existing \
              --outdir data/raw
        else
            if [ "{input.samples}" != "{output.out}" ]; then
                mkdir -p "$(dirname {output.out})"
                cp -f {input.samples} {output.out}
            fi
        fi
        """

# -------------------------------
# Validate samples.tsv schema and platform/path consistency
# -------------------------------
HELPER_SCRIPT = SCRIPTS_DIR / "read_samples_tsv.py"
assert HELPER_SCRIPT.exists(), f"Helper script missing: {HELPER_SCRIPT}"

rule check_samples_headers:
    input:
        str(SAMPLES_TSV_OUT)
    output:
        touch("reports/samples_header_check.ok")
    message:
        "Validating samples TSV schema and platform/path consistency"
    run:
        import json, subprocess
        from pathlib import Path
        p = subprocess.run([str(HELPER_SCRIPT), str(input[0])], capture_output=True, text=True, check=True)
        data = json.loads(p.stdout or "{}")
        if "error" in data:
            raise ValueError(f"samples.tsv error: {data['error']}")
        samples = data.get("samples", [])
        errs = []
        for s in samples:
            sid = (s.get("sample_id") or "").strip()
            plat = (s.get("platform") or "").strip().lower()
            rpath = (s.get("read_path") or "").strip()
            r1 = (s.get("read_path_r1") or "").strip()
            r2 = (s.get("read_path_r2") or "").strip()

            if plat not in ("ont", "illumina"):
                errs.append(f"{sid}: unsupported platform '{plat}'")
                continue

            if plat == "ont":
                # ONT should use read_path; warn/error if R1/R2 are used without read_path
                if (r1 or r2) and not rpath:
                    errs.append(f"{sid}: ONT given read_path_r1/read_path_r2 but read_path is empty; likely input error.")
            else:
                # Illumina should use read_path_r1/_r2; error if ONT-style read_path is used alone
                if rpath and not (r1 or r2):
                    errs.append(f"{sid}: Illumina given read_path (ONT style); expected read_path_r1/read_path_r2.")
                if not r1:
                    errs.append(f"{sid}: Illumina missing read_path_r1.")
                if not r2:
                    errs.append(f"{sid}: Illumina missing read_path_r2.")

        if errs:
            raise ValueError("samples.tsv validation errors:\n- " + "\n- ".join(errs))
        Path("reports").mkdir(parents=True, exist_ok=True)
        Path(output[0]).touch()

# -------------------------------
# QC rules (NanoPlot + validation)
# -------------------------------
rule validate_fastq_gz:
    input:
        fastq=lambda wc: raw_reads_dict()[wc.sample],
        samples_tsv=str(SAMPLES_TSV_OUT)
    output:
        touch("results/qc/{sample}/.validated")
    conda:
        "envs/ont-qc.yaml"
    threads: 1
    message:
        "Validating gzip for {wildcards.sample}"
    shell:
        r"""
        set -euo pipefail
        CATGZ="$(command -v gzcat || true)"
        if [ -n "$CATGZ" ]; then
            "$CATGZ" -t {input.fastq} >/dev/null
        else
            zcat -t {input.fastq} >/dev/null
        fi
        mkdir -p "$(dirname {output})"
        touch {output}
        """

rule nanoplot_qc:
    input:
        reads=lambda wc: raw_reads_dict()[wc.sample],
        validated="results/qc/{sample}/.validated"
    output:
        nanoplot_dir=directory("results/qc/{sample}/nanoplot"),
        nanoplot_html="results/qc/{sample}/nanoplot/NanoPlot-report.html",
        nanoplot_log="results/qc/{sample}/nanoplot/NanoPlot-log.txt"
    conda:
        "envs/ont-qc.yaml"
    threads: 4
    message:
        "Running NanoPlot QC for {wildcards.sample}"
    shell:
        r"""
        set -euo pipefail
        outdir="results/qc/{wildcards.sample}/nanoplot"
        mkdir -p "$outdir"

        # Diagnostics
        echo "Python: $(python --version)" >&2 || true
        echo "NanoPlot path: $(command -v NanoPlot || true)" >&2
        echo "NanoPlot version:" >&2
        NanoPlot --version >&2 || true

        # Use Agg backend to avoid GUI issues
        export MPLBACKEND=Agg

        # Run and if it fails, dump any log and exit
        if ! NanoPlot \
          --fastq {input.reads} \
          --outdir "$outdir" \
          --threads {threads} \
          --verbose \
          --maxlength 2000000 \
          -f png json \
          2> "$outdir/NanoPlot-log.txt"
        then
          echo "NanoPlot failed. Stderr follows:" >&2
          sed -n '1,200p' "$outdir/NanoPlot-log.txt" >&2 || true
          exit 2
        fi

        """

rule qc_index:
    input:
        str(SAMPLES_TSV_OUT),
        expand("results/qc/{sample}/nanoplot/NanoPlot-report.html", sample=samples_list())
    output:
        "results/qc/index.html"
    message:
        "Building QC index"
    run:
        out = []
        out.append("<!doctype html><meta charset='utf-8'><title>QC index</title>")
        out.append("<h1>QC reports</h1><ul>")
        for s in samples_list():
            out.append(f"<li><a href='{s}/nanoplot/NanoPlot-report.html'>{s}</a></li>")
        out.append("</ul>")
        Path("results/qc").mkdir(parents=True, exist_ok=True)
        Path("results/qc/index.html").write_text("\n".join(out))
        
# =========================
# ONT bacterial WGS: assembly, polishing, QC, annotation
# Uses config.yaml for parameters and paths.
# =========================

import os

SAMPLES = [cfg("sample", "Ecoli30x")]
REF = cfg("reference", "resources/reference/ecoli_k12_mg1655.fasta")
use_bakta = bool(cfg("annotation.use_bakta", False))
use_prokka = bool(cfg("annotation.use_prokka", False))

def reads_path(wc):
    return cfg(f"reads.{wc.sample}", "")

def get_reads_for_assembly(wc):
    if cfg("filtering.enabled", True):
        return f"results/filtered/{wc.sample}.fastq.gz"
    else:
        return reads_path(wc)



########################################
# Filtering (optional, Filtlong)
########################################

rule filter_reads:
    input:
        reads=lambda wc: reads_path(wc)
    output:
        "results/filtered/{sample}.fastq.gz"
    threads: int(cfg("threads.filtlong", 4))
    conda: "envs/filter.yaml"
    params:
        enabled=lambda wc: cfg("filtering.enabled", True),
        min_len=lambda wc: int(cfg("filtering.min_length", 1000)),
        keep_pct=lambda wc: int(cfg("filtering.keep_percent", 95))
    shell:
        r"""
        set -euo pipefail
        if [ "{params.enabled}" = "True" ] || [ "{params.enabled}" = "true" ]; then
            filtlong --min_length {params.min_len} --keep_percent {params.keep_pct} {input.reads} | gzip -c > {output}
        else
            mkdir -p "$(dirname {output})"
            ln -sf "$(readlink -f {input.reads} || echo {input.reads})" {output}
        fi
        """


########################################
# Assembly (Flye)
########################################
rule flye_assemble:
    input:
        reads=get_reads_for_assembly
    output:
        asm="results/assembly/{sample}/flye/assembly.fasta",
        outdir=directory("results/assembly/{sample}/flye")
    threads: int(cfg("threads.flye", 8))
    conda: "envs/flye.yaml"
    params:
        genome_size=cfg("genome_size", "4.6m")
    shell:
        r"""
        set -euo pipefail
        test -s {input.reads} || (echo "ERROR: reads missing: {input.reads}" >&2; exit 1)
        flye \
          --nano-raw {input.reads} \
          --genome-size {params.genome_size} \
          --threads {threads} \
          --out-dir {output.outdir}
        # Normalize output: ensure {output.asm} exists even if Flye gzips it
        if [ -f "{output.asm}" ]; then
            :
        elif [ -f "{output.outdir}/assembly.fasta.gz" ]; then
            gzip -dc "{output.outdir}/assembly.fasta.gz" > "{output.asm}"
        else
            echo "Flye did not produce assembly.fasta(.gz) in {output.outdir}" >&2
            ls -lah "{output.outdir}" >&2 || true
            exit 1
        fi
        """

########################################
# Racon polishing x2 (minimap2 + racon)
########################################


rule racon_r1:
    input:
        reads="results/filtered/{sample}.fastq.gz",
        paf="results/assembly/{sample}/r1.paf.gz",
        draft="results/assembly/{sample}/flye/assembly.fasta"
    output:
        "results/assembly/{sample}/racon1.fasta"
    threads: int(cfg("threads.racon", 4))
    conda: "envs/polish.yaml"
    shell:
        r"""
        set -euo pipefail
        racon -t {threads} {input.reads} {input.paf} {input.draft} > {output}
        """

rule racon_r2:
    input:
        reads="results/filtered/{sample}.fastq.gz",
        paf="results/assembly/{sample}/r2.paf.gz",
        draft="results/assembly/{sample}/racon1.fasta"
    output:
        "results/assembly/{sample}/racon2.fasta"
    threads: int(cfg("threads.racon", 4))
    conda: "envs/polish.yaml"
    shell:
        r"""
        set -euo pipefail
        racon -t {threads} {input.reads} {input.paf} {input.draft} > {output}
        """

rule map_to_asm_r1:
    input:
        asm="results/assembly/{sample}/flye/assembly.fasta",
        reads="results/filtered/{sample}.fastq.gz"
    output:
        "results/assembly/{sample}/r1.paf.gz"
    threads: int(cfg("threads.minimap2", 4))
    conda: "envs/polish.yaml"
    shell:
        r"""
        set -euo pipefail
        minimap2 -x map-ont -t {threads} {input.asm} {input.reads} | gzip -c > {output}
        """

rule map_to_asm_r2:
    input:
        asm="results/assembly/{sample}/racon1.fasta",
        reads="results/filtered/{sample}.fastq.gz"
    output:
        "results/assembly/{sample}/r2.paf.gz"
    threads: int(cfg("threads.minimap2", 4))
    conda: "envs/polish.yaml"
    shell:
        r"""
        set -euo pipefail
        minimap2 -x map-ont -t {threads} {input.asm} {input.reads} | gzip -c > {output}
        """


########################################
# Medaka polishing
########################################

rule medaka:
    input:
        reads=get_reads_for_assembly,
        asm="results/assembly/{sample}/racon2.fasta"
    output:
        consensus="results/assembly/{sample}/medaka/consensus.fasta.gz"
    threads: int(cfg("threads.medaka",8))
    conda: "envs/medaka.yaml"
    params:
        model=cfg("medaka_model", "r104_e81_sup_g615")
    shell:
        r"""
        set -euo pipefail
        outdir="results/assembly/{wildcards.sample}/medaka" \
        mkdir -p "$outdir" \
        medaka_consensus \
          -i {input.reads} \
          -d {input.asm} \
          -o "$outdir" \
          -t {threads} \
          -m {params.model}
        # Normalize to .fasta.gz for deterministic downstream input:
        if [ -f "$outdir/consensus.fasta.gz" ]; then
            ln -sf "$outdir/consensus.fasta.gz" "{output.consensus}"ln -sf "consensus.fasta.gz" "{output.consensus}"
        elif [ -f "$outdir/consensus.fasta" ]; then
            gzip -c "$outdir/consensus.fasta" > "{output.consensus}"
        else
            echo "Medaka did not produce consensus.fasta(.gz) in $outdir" >&2
            ls -lah "$outdir" >&2 || true
            exit 1
        fi
        """

rule final_assembly:
    input:
        gz="results/assembly/{sample}/medaka/consensus.fasta.gz"
    output:
        fa="results/assembly/{sample}/final.fasta"
    shell:
        r"""
        set -euo pipefail
        gzip -cd {input.gz} > {output.fa}
        """

########################################
# Mapping and coverage QC
########################################

rule map_reads_final:
    input:
        asm="results/assembly/{sample}/final.fasta",
        reads=get_reads_for_assembly
    output:
        bam="results/assembly/{sample}/coverage/{sample}.bam",
        bai="results/assembly/{sample}/coverage/{sample}.bam.bai"
    threads: int(cfg("threads.minimap2", 8))
    conda: "envs/flye.yaml"
    shell:
        r"""
        set -euo pipefail
        mkdir -p results/assembly/{wildcards.sample}/coverage
        minimap2 -x map-ont -t {threads} {input.asm} {input.reads} \
          | samtools sort -@ {threads} -o {output.bam}
        samtools index {output.bam}
        """

rule depth_summary:
    input:
        bam="results/assembly/{sample}/coverage/{sample}.bam"
    output:
        "results/assembly/{sample}/coverage/depth.txt"
    threads: 2
    conda: "envs/flye.yaml"
    shell:
        r"""
        set -euo pipefail
        samtools depth -a {input.bam} \
          | awk '{{sum+=$3; n++}} END {{if(n>0) print "Mean depth:", sum/n; else print "Mean depth: 0"}}' \
          > {output}
        """

########################################
# QUAST against reference
########################################

rule quast:
    input:
        asm="results/assembly/{sample}/final.fasta",
        ref=REF
    output:
        directory("results/qc/{sample}/quast")
    threads: int(cfg("threads.quast", 4))
    conda: "envs/quast.yaml"
    shell:
        r"""
        set -euo pipefail
        quast {input.asm} -r {input.ref} -o {output} -t {threads}
        """

########################################
# Annotation (choose Bakta and/or Prokka via config)
########################################

rule annotate_bakta:
    input:
        asm="results/assembly/{sample}/final.fasta"
    output:
        # Bakta writes multiple files; ensure a key one exists:
        "results/annotation/{sample}/bakta/annotation.gff"
    threads: int(cfg("threads.annotate", 8))
    conda: "envs/annotate_bakta.yaml"
    params:
        db=cfg("annotation.bakta_db", "~/.cache/bakta/db")
    shell:
        r"""
        set -euo pipefail
        outdir="results/annotation/{wildcards.sample}/bakta"
        mkdir -p "$outdir"
        bakta --db {params.db} --threads {threads} --output "$outdir" {input.asm}
        # Create a stable path for Snakemake's expected output
        # Bakta typically writes <prefix>.gff; symlink or copy to annotation.gff
        gff="$(ls "$outdir"/*.gff | head -n1)"
        cp "$gff" "{output}"
        """

rule annotate_prokka:
    input:
        asm="results/assembly/{sample}/final.fasta"
    output:
        "results/annotation/{sample}/prokka/{sample}.gff"
    threads: int(cfg("threads.annotate", 8))
    conda: "envs/annotate_prokka.yaml"
    shell:
        r"""
        set -euo pipefail
        outdir="results/annotation/{wildcards.sample}/prokka"
        mkdir -p "$outdir"
        prokka \
          --outdir "$outdir" \
          --prefix {wildcards.sample} \
          --cpus {threads} \
          {input.asm}
        """

########################################
# Convenience aggregates
########################################

rule qc_bundle:
    input:
        expand("results/assembly/{sample}/coverage/depth.txt", sample=SAMPLES),
        expand("results/qc/{sample}/quast/report.txt", sample=SAMPLES)
    message:
        "QC bundle ready."


# -------------------------------
# Default target
# -------------------------------
rule all:
    input:
        #Fetch/manifest + QC index
        str(SAMPLES_TSV_OUT),
        "reports/manifest_validation.txt",
        "reports/manifest_validation.json",
        "reports/samples_header_check.ok",
        "results/qc/index.html",
        # Assembly deliverables (config-driven)
        expand("results/assembly/{sample}/final.fasta", sample=SAMPLES),
        expand("results/qc/{sample}/quast/report.txt", sample=SAMPLES),
        # Optional: annotation deliverables depending on config toggles
        expand("results/annotation/{sample}/bakta/annotation.gff", sample=SAMPLES) if use_bakta else [],
        expand("results/annotation/{sample}/prokka/{sample}.gff", sample=SAMPLES) if use_prokka else []